{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取原始数据文件\n",
    "df1 = pd.read_csv(r'D:\\songyue\\tongtong\\final_data.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "匹配性别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取原始数据文件\n",
    "xingbie = pd.read_csv(r'D:\\songyue\\性别\\result\\result.csv', header=None)\n",
    "\n",
    "# 添加列名\n",
    "xingbie.columns = [\"o_id\", \"姓名\", \"性别\"]\n",
    "\n",
    "# 显示数据框的前几行以验证\n",
    "print(xingbie.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依据唯一ID列，将df2中的US排名2023合并到frequency_distribution\n",
    "merged_df_new2 = pd.merge(df1, xingbie[[\"o_id\", \"性别\"]], on='o_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_new2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_new2 = merged_df_new2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "匹配专业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取原始数据文件\n",
    "zhuanye = pd.read_csv('D:\\songyue\\专业清洗\\待标注数据3_预测结果-mm.csv')\n",
    "# 重命名唯一ID4为唯一ID\n",
    "zhuanye = zhuanye.rename(columns={'数据': 'department_name'})\n",
    "zhuanye= zhuanye.drop_duplicates()\n",
    "# 依据唯一ID列，将df2中的US排名2023合并到frequency_distribution\n",
    "merged_df_new3 = pd.merge(merged_df_new2, zhuanye[['department_name', '171类',\"30类\",\"11类\",\"3类\"]], on='department_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_new3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_new3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_new3 = merged_df_new3.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df_new3.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不区分样本：不同学历的'唯一ID'统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 按照 'o_id' 和 'start_year_origin' 升序排列\n",
    "merged_df_new3_sorted = merged_df_new3.sort_values(by=['o_id', 'start_year_origin'])\n",
    "merged_df_new3_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 按照 'o_id' 和 'start_year_origin' 升序排列\n",
    "# merged_df_new3_sorted = merged_df_new3.sort_values(by=['o_id', 'start_year_origin'])\n",
    "\n",
    "# 定义一个函数来获取样本并统计频率\n",
    "def get_sample_and_count_frequency(df, filter_column, filter_value):\n",
    "    # 筛选出特定条件的行\n",
    "    sub_sample = df[df[filter_column] == filter_value]\n",
    "    \n",
    "    # 按 'o_id' 分组，取每组的最后一行\n",
    "    last_rows = sub_sample.groupby('o_id').last().reset_index()\n",
    "    \n",
    "    # 统计 '唯一ID' 列的频率\n",
    "    frequency_counts = last_rows['唯一ID'].value_counts().reset_index()\n",
    "    frequency_counts.columns = ['唯一ID', '频率']\n",
    "    \n",
    "    return frequency_counts\n",
    "\n",
    "# 统计 '本科统计' 为 1 的样本\n",
    "undergraduate_frequency = get_sample_and_count_frequency(merged_df_new3_sorted, '本科统计', 1)\n",
    "\n",
    "# 统计 '硕士统计' 为 1 的样本\n",
    "master_frequency = get_sample_and_count_frequency(merged_df_new3_sorted, '硕士统计', 1)\n",
    "\n",
    "# 统计 '博士统计' 为 1 的样本\n",
    "doctoral_frequency = get_sample_and_count_frequency(merged_df_new3_sorted, '博士统计', 1)\n",
    "\n",
    "# 输出结果\n",
    "print(\"本科统计样本的唯一ID频率分布：\")\n",
    "print(undergraduate_frequency)\n",
    "\n",
    "print(\"\\n硕士统计样本的唯一ID频率分布：\")\n",
    "print(master_frequency)\n",
    "\n",
    "print(\"\\n博士统计样本的唯一ID频率分布：\")\n",
    "print(doctoral_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果到 Excel 文件\n",
    "output_file_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\不同学历——全球的机构分布\\frequency_distribution.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_file_path) as writer:\n",
    "    undergraduate_frequency.to_excel(writer, sheet_name='本科统计', index=False)\n",
    "    master_frequency.to_excel(writer, sheet_name='硕士统计', index=False)\n",
    "    doctoral_frequency.to_excel(writer, sheet_name='博士统计', index=False)\n",
    "\n",
    "print(f\"\\n结果已保存到: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "区分样本：分析有工作的样本——当前工作机构与本科院校层次的关系\n",
    "筛选merged_df_new3_sorted 的'工作统计新'取值为1的行的\"o_id”列唯一取值得到一个列表，然后从merged_df_new3_sorted 的'教育统计新'取值为1的行的\"o_id”列唯一取值得到一个列表2，然后得到两个列表的交集的“o_id”的集合。然后从merged_df_new3_sorted取出相应的样本，可以做到吗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 merged_df_new3_sorted 已经定义并按 'o_id' 和 'start_year_origin' 排序\n",
    "\n",
    "# 筛选 '工作统计新' 列为 1 的行，并获取 'o_id' 的唯一值\n",
    "o_id_work = merged_df_new3_sorted[merged_df_new3_sorted['工作统计新'] == 1]['o_id'].unique()\n",
    "\n",
    "# 筛选 '教育统计新' 列为 1 的行，并获取 'o_id' 的唯一值\n",
    "o_id_education = merged_df_new3_sorted[merged_df_new3_sorted['教育统计新'] == 1]['o_id'].unique()\n",
    "\n",
    "# 计算两个列表的交集\n",
    "common_o_ids = set(o_id_work).intersection(set(o_id_education))\n",
    "\n",
    "# 从 merged_df_new3_sorted 中筛选出这些交集对应的样本\n",
    "filtered_samples = merged_df_new3_sorted[merged_df_new3_sorted['o_id'].isin(common_o_ids)]\n",
    "\n",
    "# 输出结果\n",
    "print(\"符合条件的样本：\")\n",
    "print(filtered_samples)\n",
    "\n",
    "# 可选：保存结果到 Excel\n",
    "output_filtered_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\符合条件的样本（有工作）.csv\"\n",
    "filtered_samples.to_csv(output_filtered_path, index=False)\n",
    "print(f\"\\n结果已保存到: {output_filtered_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 filtered_samples 中 o_id 的个数\n",
    "o_id_count = filtered_samples['o_id'].nunique()\n",
    "print(f\"符合条件的样本中 o_id 的个数为：{o_id_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_samples.shape)\n",
    "print(filtered_samples.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 按照 'o_id' 和 'start_year_origin' 升序排列\n",
    "# merged_df_new3_sorted = merged_df_new3.sort_values(by=['o_id', 'start_year_origin'])\n",
    "\n",
    "# 定义一个函数来获取样本并统计频率\n",
    "def get_sample_and_count_frequency(df, filter_column, filter_value):\n",
    "    # 筛选出特定条件的行\n",
    "    sub_sample = df[df[filter_column] == filter_value]\n",
    "    \n",
    "    # 按 'o_id' 分组，取每组的最后一行\n",
    "    last_rows = sub_sample.groupby('o_id').last().reset_index()\n",
    "    \n",
    "    # 统计 '唯一ID' 列的频率\n",
    "    frequency_counts = last_rows['唯一ID'].value_counts().reset_index()\n",
    "    frequency_counts.columns = ['唯一ID', '频率']\n",
    "    \n",
    "    return frequency_counts\n",
    "\n",
    "# 统计 '本科统计' 为 1 的样本\n",
    "undergraduate_frequency = get_sample_and_count_frequency(filtered_samples, '本科统计', 1)\n",
    "\n",
    "# 统计 '硕士统计' 为 1 的样本\n",
    "master_frequency = get_sample_and_count_frequency(filtered_samples, '硕士统计', 1)\n",
    "\n",
    "# 统计 '博士统计' 为 1 的样本\n",
    "doctoral_frequency = get_sample_and_count_frequency(filtered_samples, '博士统计', 1)\n",
    "\n",
    "# 输出结果\n",
    "print(\"本科统计样本的唯一ID频率分布：\")\n",
    "print(undergraduate_frequency)\n",
    "\n",
    "print(\"\\n硕士统计样本的唯一ID频率分布：\")\n",
    "print(master_frequency)\n",
    "\n",
    "print(\"\\n博士统计样本的唯一ID频率分布：\")\n",
    "print(doctoral_frequency)\n",
    "# 保存结果到 Excel 文件\n",
    "output_file_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\不同学历——全球的机构分布\\有工作教育样本\\frequency_distribution.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_file_path) as writer:\n",
    "    undergraduate_frequency.to_excel(writer, sheet_name='本科统计', index=False)\n",
    "    master_frequency.to_excel(writer, sheet_name='硕士统计', index=False)\n",
    "    doctoral_frequency.to_excel(writer, sheet_name='博士统计', index=False)\n",
    "\n",
    "print(f\"\\n结果已保存到: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出 filtered_samples 的前 1000 行到 Excel 文件\n",
    "output_filtered_samples_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\filtered_samples_top_1000.xlsx\"\n",
    "\n",
    "# 获取前 1000 行\n",
    "top_1000_samples = filtered_samples.head(1000)\n",
    "\n",
    "# 保存到 Excel\n",
    "top_1000_samples.to_excel(output_filtered_samples_path, index=False)\n",
    "\n",
    "print(f\"\\n前 1000 行已保存到: {output_filtered_samples_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最高学历分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 筛选 '教育统计新' 列为 1 的行，得到 edu 子数据\n",
    "edu = filtered_samples[filtered_samples['教育统计新'] == 1]\n",
    "\n",
    "# 获取所有 \"o_id\" 的唯一取值集合\n",
    "list1 = set(edu['o_id'].unique())\n",
    "\n",
    "# 列表2：获取最高学历为博士的 o_id 集合\n",
    "list2 = set(edu[edu['博士统计'] == 1]['o_id'].unique())\n",
    "\n",
    "# 列表3：从列表1中剔除列表2的 o_id 集合\n",
    "list3 = list1 - list2\n",
    "\n",
    "# 列表4：在列表3中获取“硕士统计”列取值为1的 o_id 集合\n",
    "list4 = set(edu[(edu['o_id'].isin(list3)) & (edu['硕士统计'] == 1)]['o_id'].unique())\n",
    "\n",
    "# 列表5：从列表3中剔除列表4的 o_id 集合\n",
    "list5 = list3 - list4\n",
    "\n",
    "# 列表6：在列表5中获取“本科统计”列取值为1的 o_id 集合\n",
    "list6 = set(edu[(edu['o_id'].isin(list5)) & (edu['本科统计'] == 1)]['o_id'].unique())\n",
    "\n",
    "# 计算各列表中 o_id 的数量\n",
    "print(f\"列表1中 o_id 个数：{len(list1)}\")\n",
    "print(f\"列表2中 o_id 个数：{len(list2)}\")\n",
    "print(f\"列表3中 o_id 个数：{len(list3)}\")\n",
    "print(f\"列表4中 o_id 个数：{len(list4)}\")\n",
    "print(f\"列表5中 o_id 个数：{len(list5)}\")\n",
    "print(f\"列表6中 o_id 个数：{len(list6)}\")\n",
    "\n",
    "# 获取最高学历不详的 o_id 集合\n",
    "unknown_education_o_ids = list1 - list2 - list4 - list6\n",
    "print(f\"最高学历不详的样本 o_id 列表：{unknown_education_o_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建一个字典以便于构建 DataFrame\n",
    "data = {\n",
    "    'o_id': [],\n",
    "    '最高学历': []\n",
    "}\n",
    "\n",
    "# 添加博士样本\n",
    "data['o_id'].extend(list2)\n",
    "data['最高学历'].extend(['博士'] * len(list2))\n",
    "\n",
    "# 添加硕士样本\n",
    "data['o_id'].extend(list4)\n",
    "data['最高学历'].extend(['硕士'] * len(list4))\n",
    "\n",
    "# 添加疑似本科样本\n",
    "data['o_id'].extend(list6)\n",
    "data['最高学历'].extend(['本科'] * len(list6))\n",
    "\n",
    "# 添加最高学历不详的样本\n",
    "data['o_id'].extend(unknown_education_o_ids)\n",
    "data['最高学历'].extend(['最高学历不详'] * len(unknown_education_o_ids))\n",
    "\n",
    "# 创建 DataFrame\n",
    "result_df = pd.DataFrame(data)\n",
    "\n",
    "# 输出结果 DataFrame\n",
    "print(result_df)\n",
    "\n",
    "# 保存到 Excel 文件（可选）\n",
    "output_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\不同学历——全球的机构分布\\有工作教育样本\\最高学历统计.csv\"\n",
    "result_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n结果已保存到: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行频率统计\n",
    "frequency_counts = result_df['最高学历'].value_counts().reset_index()\n",
    "frequency_counts.columns = ['最高学历', '数量']\n",
    "\n",
    "# 输出频率统计结果\n",
    "print(\"学历频率统计：\")\n",
    "print(frequency_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 work_edu 已经定义\n",
    "\n",
    "# 筛选条件：最高学历为博士，教育统计为1，并按“o_id”分组，获取“教育统计新”最后一行数据\n",
    "edu_doc = (work_edu[(work_edu['最高学历'] == '博士') & (work_edu['教育统计'] == 1)]\n",
    "           .groupby('o_id')\n",
    "           .apply(lambda x: x.iloc[-1])\n",
    "           [['o_id', '教育统计新']])\n",
    "\n",
    "# 筛选条件：最高学历为博士，工作统计新为1，并按“o_id”分组，获取“工作统计新”最后一行数据\n",
    "work_doc = (work_edu[(work_edu['最高学历'] == '博士') & (work_edu['工作统计新'] == 1)]\n",
    "            .groupby('o_id')\n",
    "            .apply(lambda x: x.iloc[-1])\n",
    "            [['o_id', '工作统计新', 'type']])\n",
    "\n",
    "# 输出 work_doc 的 type 列中各取值的频率\n",
    "type_frequencies = work_doc['type'].value_counts()\n",
    "print(\"work_doc 的 type 列各个取值的频率：\\n\", type_frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 work_edu 已经定义\n",
    "\n",
    "# 筛选条件：最高学历为博士，教育统计为1，并按“o_id”分组，获取“教育统计新”最后一行数据\n",
    "edu_mas = (work_edu[(work_edu['最高学历'] == '博士') & (work_edu['教育统计'] == 1)]\n",
    "           .groupby('o_id')\n",
    "           .apply(lambda x: x.iloc[-1])\n",
    "           [['o_id', '教育统计新']])\n",
    "\n",
    "# 筛选条件：最高学历为博士，工作统计新为1，并按“o_id”分组，获取“工作统计新”最后一行数据\n",
    "work_mas = (work_edu[(work_edu['最高学历'] == '博士') & (work_edu['工作统计新'] == 1)]\n",
    "            .groupby('o_id')\n",
    "            .apply(lambda x: x.iloc[-1])\n",
    "            [['o_id', '工作统计新', 'type']])\n",
    "\n",
    "# 输出 work_doc 的 type 列中各取值的频率\n",
    "type_frequencies = work_mas['type'].value_counts()\n",
    "print(\"work_doc 的 type 列各个取值的频率：\\n\", type_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 work_edu 已经定义\n",
    "\n",
    "# 筛选条件：最高学历为博士，教育统计为1，并按“o_id”分组，获取“教育统计新”最后一行数据\n",
    "edu_bac = (work_edu[(work_edu['最高学历'] == '博士') & (work_edu['教育统计'] == 1)]\n",
    "           .groupby('o_id')\n",
    "           .apply(lambda x: x.iloc[-1])\n",
    "           [['o_id', '教育统计新']])\n",
    "\n",
    "# 筛选条件：最高学历为博士，工作统计新为1，并按“o_id”分组，获取“工作统计新”最后一行数据\n",
    "work_bac = (work_edu[(work_edu['最高学历'] == '博士') & (work_edu['工作统计新'] == 1)]\n",
    "            .groupby('o_id')\n",
    "            .apply(lambda x: x.iloc[-1])\n",
    "            [['o_id', '工作统计新', 'type']])\n",
    "\n",
    "# 输出 work_doc 的 type 列中各取值的频率\n",
    "type_frequencies = work_bac['type'].value_counts()\n",
    "print(\"work_doc 的 type 列各个取值的频率：\\n\", type_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 work_edu 已经定义\n",
    "\n",
    "# 筛选条件：最高学历为博士，教育统计为1，并按“o_id”分组，获取“教育统计新”最后一行数据\n",
    "edu_unsure = (work_edu[(work_edu['最高学历'] == '博士') & (work_edu['教育统计'] == 1)]\n",
    "           .groupby('o_id')\n",
    "           .apply(lambda x: x.iloc[-1])\n",
    "           [['o_id', '教育统计新']])\n",
    "\n",
    "# 筛选条件：最高学历为博士，工作统计新为1，并按“o_id”分组，获取“工作统计新”最后一行数据\n",
    "work_unsure = (work_edu[(work_edu['最高学历'] == '博士') & (work_edu['工作统计新'] == 1)]\n",
    "            .groupby('o_id')\n",
    "            .apply(lambda x: x.iloc[-1])\n",
    "            [['o_id', '工作统计新', 'type']])\n",
    "\n",
    "# 输出 work_doc 的 type 列中各取值的频率\n",
    "type_frequencies = work_unsure['type'].value_counts()\n",
    "print(\"work_doc 的 type 列各个取值的频率：\\n\", type_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 edu_doc、work_doc、edu_mas、work_mas、edu_bac、work_bac 已经定义\n",
    "\n",
    "# 定义横向合并函数，包含后缀和学历类型标记\n",
    "def merge_horizontal(edu_df, work_df, edu_suffix, work_suffix, degree_type):\n",
    "    merged_df = pd.merge(\n",
    "        edu_df.add_suffix(edu_suffix), \n",
    "        work_df.add_suffix(work_suffix), \n",
    "        left_index=True, \n",
    "        right_index=True, \n",
    "        how='outer'\n",
    "    )\n",
    "    merged_df['教育类型'] = degree_type\n",
    "    return merged_df\n",
    "\n",
    "# 逐个合并博士、硕士和本科的 edu 和 work 数据框\n",
    "merged_doc = merge_horizontal(edu_doc, work_doc, '_edu', '_work', '博士')\n",
    "merged_mas = merge_horizontal(edu_mas, work_mas, '_edu', '_work', '硕士')\n",
    "merged_bac = merge_horizontal(edu_bac, work_bac, '_edu', '_work', '本科')\n",
    "\n",
    "# 将三个合并后的数据框纵向合并\n",
    "final_merged_df = pd.concat([merged_doc, merged_mas, merged_bac], ignore_index=True)\n",
    "\n",
    "# 查看合并后的结果\n",
    "print(final_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择需要保留的列并重命名\n",
    "final_merged_df = final_merged_df.rename(columns={\n",
    "    '教育统计_edu': '教育统计',\n",
    "    '工作统计新_edu': '工作统计新',\n",
    "    '教育统计新_edu': '教育统计新',\n",
    "    '性别_edu': '性别',\n",
    "    '最高学历_edu': '最高学历',\n",
    "    'o_id_edu': 'o_id'\n",
    "})\n",
    "\n",
    "# 删除多余列\n",
    "final_merged_df = final_merged_df.drop(columns=[\n",
    "    '教育统计_work', '工作统计新_work', '教育统计新_work', '性别_work', '最高学历_work', 'o_id_work'\n",
    "])\n",
    "\n",
    "final_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 final_merged_df 保存为 CSV 文件\n",
    "output_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\final_merged_df.csv\"\n",
    "final_merged_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\final_merged_df.csv\"\n",
    "final_merged_df = pd.read_csv(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_merged_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "博士当前工作值为0,表明学业就业跨国；博士当前工作值为1，表明学业就业不跨国。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 添加“博士当前工作”列，判断“国家唯一ID_edu”是否等于“国家唯一ID_work”\n",
    "final_merged_df['博士当前工作'] = np.where(final_merged_df['国家唯一ID_edu'] == final_merged_df['国家唯一ID_work'], 1, 0)\n",
    "\n",
    "# 输出结果 DataFrame\n",
    "print(final_merged_df[['国家唯一ID_edu', '国家唯一ID_work', '博士当前工作']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算基尼系数：当前工作单位在大学、industry、gov、labs;最高学历分别为博士、硕士、本科、不详"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前工作单位在大学"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 final_merged_df 已经定义并包含“教育类型”、“国家唯一ID_work”、“唯一ID_edu”等列\n",
    "\n",
    "# 限制 type_work 取值为 \"university\" 且 \"博士当前工作\" 列为 1\n",
    "filtered_df = final_merged_df[(final_merged_df['type_work'] == 'university') & (final_merged_df['博士当前工作'] == 1)]\n",
    "\n",
    "# 定义用于存储结果的列表\n",
    "results = []\n",
    "\n",
    "# 根据“教育类型”分组\n",
    "for edu_type, group in filtered_df.groupby('教育类型'):\n",
    "    # 统计国家唯一ID_work频率，并取前3个国家\n",
    "    top_countries = group['国家唯一ID_work'].value_counts().head(100).index.tolist()\n",
    "    \n",
    "    # 遍历前3个国家，获取每个国家的数据\n",
    "    for country in top_countries:\n",
    "        # 筛选出属于该国家的样本\n",
    "        country_samples = group[group['国家唯一ID_work'] == country]\n",
    "        \n",
    "        # 统计唯一ID_edu的频率\n",
    "        id_counts = country_samples['唯一ID_edu'].value_counts().reset_index()\n",
    "        id_counts.columns = ['唯一ID_edu', '计数']\n",
    "        \n",
    "        # 去掉计数小于3的记录/5\n",
    "        id_counts = id_counts[id_counts['计数'] >= 6]\n",
    "        \n",
    "        # 计算剩余记录的总计数\n",
    "        valid_total_count = id_counts['计数'].sum()\n",
    "        \n",
    "        # 如果没有满足条件的记录，则跳过\n",
    "        if valid_total_count == 0:\n",
    "            continue\n",
    "        \n",
    "        # 重新计算占比\n",
    "        id_counts['占比'] = id_counts['计数'] / valid_total_count\n",
    "        \n",
    "        # 添加 o_id 列（每行中的唯一ID_edu值）\n",
    "        id_counts['o_id'] = id_counts['唯一ID_edu']\n",
    "        \n",
    "        # 添加教育类型和国家字段\n",
    "        id_counts['教育类型'] = edu_type\n",
    "        id_counts['国家'] = country\n",
    "        \n",
    "        # 将结果添加到列表中\n",
    "        results.append(id_counts)\n",
    "\n",
    "# 将所有结果合并为一个 DataFrame\n",
    "final_result_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# 输出结果表格\n",
    "print(final_result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 final_merged_df 保存为 CSV 文件\n",
    "output_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\基尼系数计算准备df--大学2.csv\"\n",
    "final_result_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前工作单位在企业会怎么样？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前工作单位在企业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 final_merged_df 已经定义并包含“教育类型”、“国家唯一ID_work”、“唯一ID_edu”等列\n",
    "\n",
    "# 限制 type_work 取值为 \"university\" 且 \"博士当前工作\" 列为 1\n",
    "filtered_df = final_merged_df[(final_merged_df['type_work'] == 'university') & (final_merged_df['博士当前工作'] == 1)]\n",
    "\n",
    "# 定义用于存储结果的列表\n",
    "results = []\n",
    "\n",
    "# 根据“教育类型”分组\n",
    "for edu_type, group in filtered_df.groupby('教育类型'):\n",
    "    # 统计国家唯一ID_work频率，并取前3个国家\n",
    "    top_countries = group['国家唯一ID_work'].value_counts().head(100).index.tolist()\n",
    "    \n",
    "    # 遍历前3个国家，获取每个国家的数据\n",
    "    for country in top_countries:\n",
    "        # 筛选出属于该国家的样本\n",
    "        country_samples = group[group['国家唯一ID_work'] == country]\n",
    "        \n",
    "        # 统计唯一ID_edu的频率\n",
    "        id_counts = country_samples['唯一ID_edu'].value_counts().reset_index()\n",
    "        id_counts.columns = ['唯一ID_edu', '计数']\n",
    "        \n",
    "        # 去掉计数小于3的记录/5\n",
    "        id_counts = id_counts[id_counts['计数'] >= 3]\n",
    "        \n",
    "        # 计算剩余记录的总计数\n",
    "        valid_total_count = id_counts['计数'].sum()\n",
    "        \n",
    "        # 如果没有满足条件的记录，则跳过\n",
    "        if valid_total_count == 0:\n",
    "            continue\n",
    "        \n",
    "        # 重新计算占比\n",
    "        id_counts['占比'] = id_counts['计数'] / valid_total_count\n",
    "        \n",
    "        # 添加 o_id 列（每行中的唯一ID_edu值）\n",
    "        id_counts['o_id'] = id_counts['唯一ID_edu']\n",
    "        \n",
    "        # 添加教育类型和国家字段\n",
    "        id_counts['教育类型'] = edu_type\n",
    "        id_counts['国家'] = country\n",
    "        \n",
    "        # 将结果添加到列表中\n",
    "        results.append(id_counts)\n",
    "\n",
    "# 将所有结果合并为一个 DataFrame\n",
    "final_result_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# 将 final_merged_df 保存为 CSV 文件\n",
    "output_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\基尼系数计算准备df--大学1.csv\"\n",
    "final_result_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 final_merged_df 已定义，查看 'type_work' 列的唯一取值\n",
    "unique_type_work_values = final_merged_df['type_work'].unique()\n",
    "unique_type_work_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并不同的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# 定义文件路径模式\n",
    "file_paths = glob.glob(r'D:\\songyue\\tongtong\\ORCID数据检查\\不同类型工作-不同学历——院校分布\\二八结果2-*.csv')\n",
    "\n",
    "# 检查找到的文件\n",
    "if not file_paths:\n",
    "    print(\"未找到任何匹配的文件，请检查文件路径和文件名模式。\")\n",
    "else:\n",
    "    print(\"找到以下文件:\", file_paths)\n",
    "\n",
    "    # 用于存储每个文件的数据框列表\n",
    "    dfs = []\n",
    "\n",
    "    # 逐个读取文件并添加 '表格名' 列\n",
    "    for file_path in file_paths:\n",
    "        # 读取文件\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # 提取文件名作为新的列值\n",
    "        table_name = file_path.split('/')[-1].replace(\"二八结果2-\", \"\").replace(\".csv\", \"\")\n",
    "        df['表格名'] = table_name  # 添加新的列 '表格名'，值为文件名（不包含扩展名）\n",
    "        \n",
    "        # 将当前数据框添加到列表中\n",
    "        dfs.append(df)\n",
    "\n",
    "    # 合并所有数据框\n",
    "    merged_dfy = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # 显示合并结果的前几行\n",
    "    print(merged_dfy.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# 定义文件路径模式（假设这些文件都在同一文件夹中，且名称中包含 \"二八结果2-\"）\n",
    "file_paths = glob.glob(r'D:\\songyue\\tongtong\\ORCID数据检查\\不同类型工作-不同学历——院校分布\\二八结果2-*.csv')\n",
    "\n",
    "# 读取每个文件并根据文件名添加后缀\n",
    "dfs = {}\n",
    "for file_path in file_paths:\n",
    "    # 提取文件名中的类型（如“企业”、“政府”等）\n",
    "    file_type = file_path.split('/')[-1].replace(\"二八结果2-\", \"\").replace(\".csv\", \"\")\n",
    "    suffix = f\"_{file_type}\"  # 添加后缀\n",
    "    \n",
    "    # 读取文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 将文件数据存入字典，键为文件后缀\n",
    "    dfs[suffix] = df\n",
    "\n",
    "# 逐步将数据框横向合并\n",
    "# 假设合并的主键为 \"教育类型\" 和 \"国家\"，且每个文件都包含这些列\n",
    "merged_df = dfs.popitem()[1]  # 初始化合并数据框为第一个读取的文件\n",
    "for suffix, df in dfs.items():\n",
    "    merged_df = pd.merge(merged_df, df, on=[\"教育类型\", \"国家\"],  how=\"outer\", suffixes=(\"\", suffix))\n",
    "\n",
    "# 查看合并后的结果\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 final_merged_df 保存为 CSV 文件\n",
    "output_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\不同类型工作-不同学历——院校分布\\二八结果2--合并1.csv\"\n",
    "merged_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前工作单位在大学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算二八法则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设df是包含数据的DataFrame\n",
    "# 按教育类型和国家分组\n",
    "grouped = final_result_df.groupby(['教育类型', '国家'])\n",
    "\n",
    "# 定义用于存储结果的列表\n",
    "results = []\n",
    "\n",
    "# 遍历每个组\n",
    "for (edu_type, country), group in grouped:\n",
    "    # 按占比降序排列\n",
    "    group = group.sort_values('占比', ascending=False)\n",
    "    # 计算累计占比\n",
    "    group['累计占比'] = group['占比'].cumsum()\n",
    "    # 找到累计占比刚好超过0.8的行\n",
    "    threshold_index = group[group['累计占比'] > 0.2].index[0]\n",
    "    # 统计唯一ID_edu数量\n",
    "    unique_id_count = group.loc[:threshold_index, '唯一ID_edu'].nunique()\n",
    "    # 计算该组总的唯一ID_edu个数\n",
    "    total_unique_id_count = group['唯一ID_edu'].nunique()\n",
    "    # 计算百分比\n",
    "    percentage = unique_id_count / total_unique_id_count * 100\n",
    "    # 将结果添加到列表\n",
    "    results.append({\n",
    "        '教育类型': edu_type,\n",
    "        '国家': country,\n",
    "        '累计占比超过0.8的唯一ID_edu个数': unique_id_count,\n",
    "        '占总唯一ID_edu个数的百分比': percentage\n",
    "    })\n",
    "\n",
    "# 转换为DataFrame\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "# 将 final_merged_df 保存为 CSV 文件\n",
    "output_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\20%的结果2-大学.csv\"\n",
    "result_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 final_merged_df 已定义\n",
    "\n",
    "# 第一步：筛选出 \"教育类型\" 为 \"university\" 且 \"博士当前工作\" 为 1 的记录\n",
    "df1 = final_merged_df[(final_merged_df['教育类型'] == \"university\") & (final_merged_df['博士当前工作'] == 1)]\n",
    "print(\"筛选后的记录数:\", len(df1))  # 检查筛选后的数据量\n",
    "\n",
    "# 第二步：按 \"国家唯一ID_work\" 和 \"教育类型\" 分组，统计每组中 \"唯一ID_work\" 和 \"唯一ID_edu\" 组合的频率，并计算占比\n",
    "results = []\n",
    "for (country_id, edu_type), group in df1.groupby(['国家唯一ID_work', '教育类型']):\n",
    "    if group.empty:\n",
    "        print(f\"No data for group: 国家唯一ID_work={country_id}, 教育类型={edu_type}\")\n",
    "    else:\n",
    "        # 统计 (唯一ID_work, 唯一ID_edu) 组合的频率\n",
    "        combo_counts = group.groupby(['唯一ID_work', '唯一ID_edu']).size().reset_index(name='计数')\n",
    "        \n",
    "        # 计算每组的总计数\n",
    "        total_count = combo_counts['计数'].sum()\n",
    "        \n",
    "        # 计算占比\n",
    "        combo_counts['占比'] = combo_counts['计数'] / total_count\n",
    "        \n",
    "        # 添加 国家唯一ID_work 和 教育类型 列\n",
    "        combo_counts['国家唯一ID_work'] = country_id\n",
    "        combo_counts['教育类型'] = edu_type\n",
    "        \n",
    "        # 将结果添加到列表中\n",
    "        results.append(combo_counts)\n",
    "\n",
    "# 检查 results 列表是否为空\n",
    "if results:\n",
    "    # 将所有分组结果合并为一个 DataFrame\n",
    "    final_result_df = pd.concat(results, ignore_index=True)\n",
    "    print(\"合并结果的前几行:\\n\", final_result_df.head())\n",
    "else:\n",
    "    print(\"No data to concatenate in results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基尼系数计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 data 是包含数据的原始 DataFrame\n",
    "# 按“教育类型”和“国家”组合进行分组\n",
    "grouped = final_result_df.groupby(['教育类型', '国家'])\n",
    "\n",
    "# 定义Excel写入路径\n",
    "output_path = r'D:\\songyue\\tongtong\\ORCID数据检查\\分组基尼系数计算2.xlsx'\n",
    "\n",
    "# 使用ExcelWriter创建一个多Sheet的Excel文件\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    # 遍历每个子 DataFrame\n",
    "    for (edu_type, country), df in grouped:\n",
    "        # 检查子数据框是否为空\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        # 计算 x 占比和 x 累计占比\n",
    "        total_rows = len(df['唯一ID_edu'])\n",
    "        df['x占比'] = 1 / total_rows\n",
    "        df['x累计占比'] = df['x占比'].cumsum()\n",
    "        \n",
    "        # 计算 y 占比和 y 累计占比\n",
    "        total_count = df['计数'].sum()\n",
    "        if total_count == 0:\n",
    "            continue\n",
    "        df['y占比'] = df['计数'] / total_count\n",
    "        df['y累计占比'] = df['y占比'].cumsum()\n",
    "        \n",
    "        # 计算梯形面积\n",
    "        df['梯形面积'] = (df['x累计占比'].diff() * (df['y累计占比'] + df['y累计占比'].shift(fill_value=0))) / 2\n",
    "        df.at[0, '梯形面积'] = (df['x累计占比'].iloc[0] * df['y累计占比'].iloc[0]) / 2\n",
    "        \n",
    "        # 重置索引，确保索引从0开始\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # 计算梯形面积之和并赋值到第一行\n",
    "        df.at[0, '梯形面积之和'] = df['梯形面积'].sum()\n",
    "\n",
    "        # 计算基尼系数并赋值到第一行\n",
    "        df.at[0, '基尼系数'] = 2 * df.at[0, '梯形面积之和'] - 1\n",
    "\n",
    "    \n",
    "        # 将当前子DataFrame写入到Excel中的一个Sheet\n",
    "        sheet_name = f\"{edu_type}_{int(country)}\"  # 创建Sheet名称\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"结果已保存到: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 data 是包含数据的原始 DataFrame\n",
    "# 按“教育类型”和“国家”组合进行分组\n",
    "grouped = final_result_df.groupby(['教育类型', '国家'])\n",
    "\n",
    "# 定义用于存储每个子df基尼系数的列表\n",
    "gini_results = []\n",
    "\n",
    "# 遍历每个子 DataFrame\n",
    "for (edu_type, country), df in grouped:\n",
    "    # 检查子数据框是否为空\n",
    "    if df.empty:\n",
    "        continue\n",
    "\n",
    "    # 计算 x 占比和 x 累计占比\n",
    "    total_rows = len(df['唯一ID_edu'])\n",
    "    df['x占比'] = 1 / total_rows\n",
    "    df['x累计占比'] = df['x占比'].cumsum()\n",
    "    \n",
    "    # 计算 y 占比和 y 累计占比\n",
    "    total_count = df['计数'].sum()\n",
    "    if total_count == 0:\n",
    "        # 如果总计数为0，则跳过该分组\n",
    "        continue\n",
    "    df['y占比'] = df['计数'] / total_count\n",
    "    df['y累计占比'] = df['y占比'].cumsum()\n",
    "    \n",
    "    # 计算梯形面积\n",
    "    df['梯形面积'] = (df['x累计占比'].diff() * (df['y累计占比'] + df['y累计占比'].shift(fill_value=0))) / 2\n",
    "    df.at[0, '梯形面积'] = (df['x累计占比'].iloc[0] * df['y累计占比'].iloc[0]) / 2\n",
    "    \n",
    "    # 重置索引，确保索引从0开始\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # 计算梯形面积之和并赋值到第一行\n",
    "    df.at[0, '梯形面积之和'] = df['梯形面积'].sum()\n",
    "\n",
    "    # 计算基尼系数并赋值到第一行\n",
    "    df.at[0, '基尼系数'] = 2 * df.at[0, '梯形面积之和'] - 1\n",
    "    \n",
    "    # 提取当前子 DataFrame 的基尼系数的第一个值\n",
    "    gini_value = df['基尼系数'].iloc[0]\n",
    "    # 检查基尼系数是否为 NaN\n",
    "    if pd.notna(gini_value):\n",
    "        gini_results.append({'教育类型': edu_type, '国家': country, '基尼系数': gini_value})\n",
    "\n",
    "# 将结果转换为 DataFrame\n",
    "gini_result_df = pd.DataFrame(gini_results)\n",
    "\n",
    "gini_result_df\n",
    "# 将 final_merged_df 保存为 CSV 文件\n",
    "output_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\基尼系数汇总2.csv\"\n",
    "gini_result_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 final_merged_df 已经定义并包含“教育类型”、“国家唯一ID_work”、“唯一ID_edu”等列\n",
    "\n",
    "# 限制 type_work 取值为 \"university\" 且 \"博士当前工作\" 列为 1\n",
    "filtered_df = final_merged_df[(final_merged_df['type_work'] == 'university') & (final_merged_df['博士当前工作'] == 0)]\n",
    "\n",
    "# 定义用于存储结果的列表\n",
    "results = []\n",
    "\n",
    "# 根据“教育类型”分组\n",
    "for edu_type, group in filtered_df.groupby('教育类型'):\n",
    "    # 统计国家唯一ID_work频率，并取前3个国家\n",
    "    top_countries = group['国家唯一ID_work'].value_counts().head(100).index.tolist()\n",
    "    \n",
    "    # 遍历前3个国家，获取每个国家的数据\n",
    "    for country in top_countries:\n",
    "        # 筛选出属于该国家的样本\n",
    "        country_samples = group[group['国家唯一ID_work'] == country]\n",
    "        \n",
    "        # 统计唯一ID_edu的频率\n",
    "        id_counts = country_samples['国家唯一ID_edu'].value_counts().reset_index()\n",
    "        id_counts.columns = ['国家唯一ID_edu', '计数']\n",
    "        \n",
    "        # 去掉计数小于3的记录\n",
    "        id_counts = id_counts[id_counts['计数'] >= 4]\n",
    "        \n",
    "        # 计算剩余记录的总计数\n",
    "        valid_total_count = id_counts['计数'].sum()\n",
    "        \n",
    "        # 如果没有满足条件的记录，则跳过\n",
    "        if valid_total_count == 0:\n",
    "            continue\n",
    "        \n",
    "        # 重新计算占比\n",
    "        id_counts['占比'] = id_counts['计数'] / valid_total_count\n",
    "        \n",
    "        # 添加 o_id 列（每行中的唯一ID_edu值）\n",
    "        id_counts['o_id'] = id_counts['国家唯一ID_edu']\n",
    "        \n",
    "        # 添加教育类型和国家字段\n",
    "        id_counts['教育类型'] = edu_type\n",
    "        id_counts['国家'] = country\n",
    "        \n",
    "        # 将结果添加到列表中\n",
    "        results.append(id_counts)\n",
    "\n",
    "# 将所有结果合并为一个 DataFrame\n",
    "final_result_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# 输出结果表格\n",
    "print(final_result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 final_merged_df 保存为 CSV 文件\n",
    "output_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\基尼系数计算准备df--海归来源国.csv\"\n",
    "final_result_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 假设 final_merged_df 已经定义并包含“教育类型”、“国家唯一ID_work”、“唯一ID_edu”等列\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 限制 type_work 取值为 \"university\" 且 \"博士当前工作\" 列为 1\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_merged_df\u001b[49m[(final_merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype_work\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniversity\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (final_merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m博士当前工作\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 定义用于存储结果的列表\u001b[39;00m\n\u001b[0;32m      9\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 final_merged_df 已经定义并包含“教育类型”、“国家唯一ID_work”、“唯一ID_edu”等列\n",
    "\n",
    "# 限制 type_work 取值为 \"university\" 且 \"博士当前工作\" 列为 1\n",
    "filtered_df = final_merged_df[(final_merged_df['type_work'] == 'university') & (final_merged_df['博士当前工作'] == 0)]\n",
    "\n",
    "# 定义用于存储结果的列表\n",
    "results = []\n",
    "\n",
    "# 根据“教育类型”分组\n",
    "for edu_type, group in filtered_df.groupby('教育类型'):\n",
    "    # 统计国家唯一ID_work频率，并取前3个国家\n",
    "    top_countries = group['国家唯一ID_work'].value_counts().head(100).index.tolist()\n",
    "    \n",
    "    # 遍历前3个国家，获取每个国家的数据\n",
    "    for country in top_countries:\n",
    "        # 筛选出属于该国家的样本\n",
    "        country_samples = group[group['国家唯一ID_work'] == country]\n",
    "        \n",
    "        # 统计唯一ID_edu的频率\n",
    "        id_counts = country_samples['唯一ID_edu'].value_counts().reset_index()\n",
    "        id_counts.columns = ['唯一ID_edu', '计数']\n",
    "        \n",
    "        # 去掉计数小于3的记录\n",
    "        # id_counts = id_counts[id_counts['计数'] >= 4]\n",
    "        \n",
    "        # 计算剩余记录的总计数\n",
    "        valid_total_count = id_counts['计数'].sum()\n",
    "        \n",
    "        # 如果没有满足条件的记录，则跳过\n",
    "        if valid_total_count == 0:\n",
    "            continue\n",
    "        \n",
    "        # 重新计算占比\n",
    "        id_counts['占比'] = id_counts['计数'] / valid_total_count\n",
    "        \n",
    "        # 添加 o_id 列（每行中的唯一ID_edu值）\n",
    "        id_counts['o_id'] = id_counts['唯一ID_edu']\n",
    "        \n",
    "        # 添加教育类型和国家字段\n",
    "        id_counts['教育类型'] = edu_type\n",
    "        id_counts['国家'] = country\n",
    "        \n",
    "        # 将结果添加到列表中\n",
    "        results.append(id_counts)\n",
    "\n",
    "# 将所有结果合并为一个 DataFrame\n",
    "final_result_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# 输出结果表格\n",
    "print(final_result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 final_merged_df 保存为 CSV 文件\n",
    "output_path = r\"D:\\songyue\\tongtong\\ORCID数据检查\\基尼系数计算准备df--海归来源校.csv\"\n",
    "final_result_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 final_merged_df 已定义\n",
    "\n",
    "# 第一步：筛选出 \"教育类型\" 为 \"university\" 且 \"博士当前工作\" 为 1 的记录\n",
    "df1 = final_merged_df[(final_merged_df['教育类型'] == \"university\") & (final_merged_df['博士当前工作'] == 1)]\n",
    "\n",
    "# 按 \"国家唯一ID_work\"、\"教育类型\" 和 \"唯一ID_work\" 分组，统计每组中 \"唯一ID_edu\" 的频率，并计算占比\n",
    "results = []\n",
    "for (country_id, edu_type, unique_work_id), group in df1.groupby(['国家唯一ID_work', '教育类型', '唯一ID_work']):\n",
    "    # 统计唯一ID_edu的频率\n",
    "    id_counts = group['唯一ID_edu'].value_counts().reset_index()\n",
    "    id_counts.columns = ['唯一ID_edu', '计数']\n",
    "    \n",
    "    # 计算总计数\n",
    "    total_count = id_counts['计数'].sum()\n",
    "    \n",
    "    # 计算占比\n",
    "    id_counts['占比'] = id_counts['计数'] / total_count\n",
    "    \n",
    "    # 添加国家唯一ID_work、教育类型 和 唯一ID_work 列\n",
    "    id_counts['国家唯一ID_work'] = country_id\n",
    "    id_counts['教育类型'] = edu_type\n",
    "    id_counts['唯一ID_work'] = unique_work_id\n",
    "    \n",
    "    # 将结果添加到列表中\n",
    "    results.append(id_counts)\n",
    "\n",
    "# 将所有分组结果合并为一个 DataFrame\n",
    "final_result_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# 查看结果\n",
    "final_result_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "区分样本：分析有工作的样本——当前工作机构与本科院校国家的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "区分样本：分析有工作，且当前工作在大学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "区分样本：分析有工作，且当前工作在企业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 '工作统计新' 和 '教育统计新' 列的唯一取值\n",
    "unique_values_work = merged_df_new3['工作统计新'].unique()\n",
    "unique_values_edu = merged_df_new3['教育统计新'].unique()\n",
    "\n",
    "# 打印唯一值列表\n",
    "print(\"工作统计新的唯一值:\", unique_values_work)\n",
    "print(\"教育统计新的唯一值:\", unique_values_edu)\n",
    "\n",
    "# 统计唯一值的个数\n",
    "unique_count_work = merged_df_new3['工作统计新'].nunique()\n",
    "unique_count_edu = merged_df_new3['教育统计新'].nunique()\n",
    "\n",
    "# 打印唯一值的数量\n",
    "print(\"工作统计新的唯一值数量:\", unique_count_work)\n",
    "print(\"教育统计新的唯一值数量:\", unique_count_edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计 '工作统计新' 和 '教育统计新' 列的组合频率\n",
    "combination_frequency = merged_df_new3[['工作统计新', '教育统计新']].value_counts().reset_index()\n",
    "# 重命名列\n",
    "combination_frequency.columns = ['工作统计新', '教育统计新', '频率']\n",
    "# 打印结果\n",
    "combination_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选出 '工作统计新' 列等于1的行\n",
    "sub_df1 = merged_df_new3[merged_df_new3['工作统计新'] == 1]\n",
    "\n",
    "# 统计 'o_id' 列的唯一取值及频率\n",
    "o_id_counts1 = sub_df1['o_id'].value_counts().reset_index()\n",
    "o_id_counts1.columns = ['o_id', '频率']\n",
    "o_id_counts1['类型'] = '工作统计'\n",
    "\n",
    "# 统计 '国家唯一ID' 列的唯一取值及频率\n",
    "unique_id_counts1 = sub_df1['国家唯一ID'].value_counts().reset_index()\n",
    "unique_id_counts1.columns = ['国家唯一ID', '频率']\n",
    "unique_id_counts1['类型'] = '工作统计'\n",
    "\n",
    "# 统计 '所在洲' 列的唯一取值及频率\n",
    "continent_counts1 = sub_df1['所在洲'].value_counts().reset_index()\n",
    "continent_counts1.columns = ['所在洲', '频率']\n",
    "continent_counts1['类型'] = '工作统计'\n",
    "\n",
    "# 筛选出 '教育统计新' 列等于1的行\n",
    "sub_df2 = merged_df_new3[merged_df_new3['教育统计新'] == 1]\n",
    "\n",
    "# 统计 'o_id' 列的唯一取值及频率\n",
    "o_id_counts2 = sub_df2['o_id'].value_counts().reset_index()\n",
    "o_id_counts2.columns = ['o_id', '频率']\n",
    "o_id_counts2['类型'] = '教育统计'\n",
    "\n",
    "# 统计 '国家唯一ID' 列的唯一取值及频率\n",
    "unique_id_counts2 = sub_df2['国家唯一ID'].value_counts().reset_index()\n",
    "unique_id_counts2.columns = ['国家唯一ID', '频率']\n",
    "unique_id_counts2['类型'] = '教育统计'\n",
    "\n",
    "# 统计 '所在洲' 列的唯一取值及频率\n",
    "continent_counts2 = sub_df2['所在洲'].value_counts().reset_index()\n",
    "continent_counts2.columns = ['所在洲', '频率']\n",
    "continent_counts2['类型'] = '教育统计'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并所有结果\n",
    "final_result = pd.concat([unique_id_counts1, continent_counts1,\n",
    "                           unique_id_counts2, continent_counts2], \n",
    "                          ignore_index=True)\n",
    "\n",
    "final_result\n",
    "final_result.to_csv(r\"D:\\songyue\\tongtong\\ORCID数据检查\\filtered_check_统计.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 定义一个通用函数来统计不同类型数据的唯一值数量\n",
    "def calculate_unique_counts(df, filter_column, filter_value, group_column, count_column, type_label):\n",
    "    # 筛选出特定条件的行\n",
    "    filtered_df = df[(df[filter_column] == filter_value) & (df[group_column].notna())]\n",
    "    \n",
    "    # 统计每个唯一取值对应的 count_column 唯一值数量\n",
    "    count_result = filtered_df.groupby(group_column)[count_column].nunique().reset_index()\n",
    "    count_result.columns = [group_column, f'{count_column}数量']\n",
    "    count_result['类型'] = type_label\n",
    "    \n",
    "    return count_result\n",
    "\n",
    "# 应用函数统计数据并合并结果\n",
    "# 统计 '国家唯一ID' 列和 '所在洲' 列的唯一取值\n",
    "o_id_counts_country_work = calculate_unique_counts(merged_df_new3, '工作统计新', 1, '国家唯一ID', 'o_id', '工作统计')\n",
    "o_id_counts_country_education = calculate_unique_counts(merged_df_new3, '教育统计新', 1, '国家唯一ID', 'o_id', '教育统计')\n",
    "\n",
    "o_id_counts_continent_work = calculate_unique_counts(merged_df_new3, '工作统计新', 1, '所在洲', 'o_id', '工作统计')\n",
    "o_id_counts_continent_education = calculate_unique_counts(merged_df_new3, '教育统计新', 1, '所在洲', 'o_id', '教育统计')\n",
    "\n",
    "# 合并所有结果\n",
    "final_result_country = pd.concat([o_id_counts_country_work, o_id_counts_country_education], ignore_index=True)\n",
    "final_result_continent = pd.concat([o_id_counts_continent_work, o_id_counts_continent_education], ignore_index=True)\n",
    "\n",
    "# 保存结果到CSV文件\n",
    "final_result_country.to_csv(r\"D:\\songyue\\tongtong\\ORCID数据检查\\filtered_check_国家唯一ID_统计.csv\", index=False)\n",
    "final_result_continent.to_csv(r\"D:\\songyue\\tongtong\\ORCID数据检查\\filtered_check_所在洲_统计.csv\", index=False)\n",
    "\n",
    "# 输出合并结果\n",
    "print(\"\\n国家唯一ID统计结果：\")\n",
    "print(final_result_country)\n",
    "print(\"\\n所在洲统计结果：\")\n",
    "print(final_result_continent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选 '频率' 大于 50 的行\n",
    "o_id_counts_filtered = o_id_counts[o_id_counts['频率'] > 50]\n",
    "\n",
    "# 打印结果\n",
    "print(\"频率大于50的 o_id 及其频率：\")\n",
    "print(o_id_counts_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选出频率大于 50 的 o_id\n",
    "o_id_high_frequency = o_id_counts[o_id_counts['频率'] > 50]['o_id']\n",
    "\n",
    "# 从 merged_df_new2 中筛选出 o_id 在 o_id_high_frequency 中的行\n",
    "filtered_df = merged_df_new2[merged_df_new2['o_id'].isin(o_id_high_frequency)]\n",
    "# 将 filtered_df 导出为 CSV 文件\n",
    "filtered_df.to_csv(r\"D:\\songyue\\tongtong\\ORCID数据检查\\filtered_check_work.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取三个CSV文件并指定数据框名称\n",
    "edu = pd.read_csv(r\"D:\\songyue\\tongtong\\每个o_id教育经历统计.csv\")\n",
    "work= pd.read_csv(r\"D:\\songyue\\tongtong\\每个o_id工作经历统计.csv\")\n",
    "allex = pd.read_csv(r\"D:\\songyue\\tongtong\\每个o_id所有经历统计.csv\")\n",
    "\n",
    "# 给每个数据框添加后缀\n",
    "# edu = edu.add_suffix('_edu')\n",
    "# work = work.add_suffix('_work')\n",
    "# allex = allex.add_suffix('_allex')\n",
    "\n",
    "# 给每个数据框除 'o_id' 列外的其他列添加后缀\n",
    "edu = edu.add_suffix('_edu').rename(columns={'o_id_edu': 'o_id'})\n",
    "work = work.add_suffix('_work').rename(columns={'o_id_work': 'o_id'})\n",
    "allex = allex.add_suffix('_allex').rename(columns={'o_id_allex': 'o_id'})\n",
    "\n",
    "# 基于 'o_id' 列进行合并\n",
    "merged_df = edu.merge(work, on='o_id', how='outer').merge(allex, on='o_id', how='outer')\n",
    "\n",
    "# 显示合并后的数据框\n",
    "merged_df\n",
    "\n",
    "# # 合并数据框（假设按行索引合并）\n",
    "# merged_df = pd.concat([df1, df2, df3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 设置字体以支持中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用黑体（SimHei）字体\n",
    "plt.rcParams['axes.unicode_minus'] = False    # 解决坐标轴负号显示问题\n",
    "\n",
    "# 假设 merged_df 是包含这些列的数据框\n",
    "# 如果还没有读取数据，请在此处将合并后的CSV文件导入为 merged_df\n",
    "# merged_df = pd.read_csv(\"merged_file.csv\")\n",
    "\n",
    "# 选择需要分析的列\n",
    "columns_to_analyze = [\n",
    "    '国家唯一ID个数_edu', '所在洲个数_edu', '城市个数_edu', 'type个数_edu', '教育统计新求和_edu', \n",
    "    '国家唯一ID个数_work', '所在洲个数_work', '城市个数_work', 'type个数_work', '工作统计新求和_work', \n",
    "    '国家唯一ID个数_allex', '所在洲个数_allex', '城市个数_allex', 'type个数_allex', \n",
    "    '教育统计新求和_allex', '工作统计新求和_allex'\n",
    "]\n",
    "# 取出这些列并计算相关系数矩阵\n",
    "correlation_matrix = merged_df[columns_to_analyze].corr()\n",
    "\n",
    "# 设置热图的尺寸\n",
    "plt.figure(figsize=(12, 10))\n",
    "# 绘制热图\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix of Selected Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "# 示例数据框（使用你实际的 merged_df）\n",
    "# merged_df = pd.read_csv(\"merged_file.csv\")\n",
    "\n",
    "# 选择需要分析的列\n",
    "columns_to_analyze = [\n",
    "    '国家唯一ID个数_edu', '所在洲个数_edu', '城市个数_edu', 'type个数_edu', '教育统计新求和_edu', \n",
    "    '国家唯一ID个数_work', '所在洲个数_work', '城市个数_work', 'type个数_work', '工作统计新求和_work', \n",
    "    '国家唯一ID个数_allex', '所在洲个数_allex', '城市个数_allex', 'type个数_allex', \n",
    "    '教育统计新求和_allex', '工作统计新求和_allex'\n",
    "]\n",
    "\n",
    "# 计算相关系数矩阵\n",
    "correlation_matrix = merged_df[columns_to_analyze].corr()\n",
    "\n",
    "# 使用层次聚类对相关系数矩阵进行重排\n",
    "linkage_matrix = linkage(correlation_matrix, method='average')\n",
    "ordered_index = leaves_list(linkage_matrix)\n",
    "\n",
    "# 根据聚类顺序重新排列矩阵\n",
    "ordered_corr_matrix = correlation_matrix.iloc[ordered_index, ordered_index]\n",
    "\n",
    "# 绘制重新排序的热图x\n",
    "plt.figure(figsize=(12, 10))\n",
    "ax = sns.heatmap(\n",
    "    ordered_corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5, \n",
    "    cbar_kws={\"orientation\": \"horizontal\"}\n",
    ")\n",
    "# plt.title(\"Reordered Correlation Matrix (After Clustering)\", y=1.1)  # 调整标题位置\n",
    "ax.xaxis.set_label_position('top')  # 设置标签位置\n",
    "ax.xaxis.tick_top()  # 将x轴的刻度移到顶部\n",
    "plt.xticks(rotation=45, ha=\"left\")  # 将横坐标标签倾斜\n",
    "# 保存图片到指定路径\n",
    "output_path = r\"D:\\songyue\\tongtong\\地理位置reordered_correlation_matrix.png\"\n",
    "plt.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
